{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ffa6af",
   "metadata": {},
   "source": [
    "This notebook predicts on 4 categories: IDD & music, IDD & rest, TDC & music, TDC & rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42bfcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a0bf1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aec38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Data/GeneratedData/combined_data/\"\n",
    "base_path = os.getcwd()\n",
    "\n",
    "# REST\n",
    "IDD_rest = np.load(os.path.join(data_path, \"IDD_rest.npy\"))\n",
    "TDC_rest = np.load(os.path.join(data_path, \"TDC_rest.npy\"))\n",
    "\n",
    "# MUSIC\n",
    "IDD_music = np.load(os.path.join(data_path, \"IDD_music.npy\"))\n",
    "TDC_music = np.load(os.path.join(data_path, \"TDC_music.npy\"))\n",
    "\n",
    "X = np.concatenate((IDD_rest, TDC_rest, IDD_music, IDD_rest))\n",
    "Y = [0]*len(IDD_rest) + [1]*len(TDC_rest) + [2]*len(IDD_music) + [3]*len(TDC_music)\n",
    "  \n",
    "Y = np.asarray(Y)\n",
    "Y = LabelBinarizer().fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb0c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.asarray(X)\n",
    "# Y = np.asarray(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37df564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16940, 14, 256)\n",
      "(16940, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82bada5",
   "metadata": {},
   "source": [
    "## Create Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63ab96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified scalogram function from Fusion notebook\n",
    "def scalogram(x, Hz, hz, start_sec, num_secs, w = 5.):\n",
    "    ''' x = time series\n",
    "        Hz = sampling rate in Hz of the input signal\n",
    "        hz = desired sampling rate (by downsampling)\n",
    "        start_sec = starting second in x\n",
    "        num_secs = total number of seconds of our clip\n",
    "        w = width parameter\n",
    "        log =raw_seiz if true take log of spectrum values\n",
    "    '''\n",
    "\n",
    "    downsample = int(round(Hz / hz))\n",
    "    X = x[start_sec * Hz: (start_sec + num_secs) * Hz : downsample]\n",
    "\n",
    "    t, dt = np.linspace(start_sec, start_sec + num_secs, hz * num_secs, retstep = True)\n",
    "    fs = 1 / dt\n",
    "\n",
    "    freq = np.linspace(1, fs / 2, int(hz / 2))\n",
    "    widths = w * fs / (2 * np.pi * freq)\n",
    "\n",
    "    cwtm = signal.cwt(X,\n",
    "                      signal.morlet2,\n",
    "                      widths,\n",
    "                      w = w)\n",
    "    \n",
    "    return cwtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9e0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scalogram(data):\n",
    "    scalogram_data = []\n",
    "    for sample in tqdm(data):\n",
    "        scalograms = []\n",
    "        for channel in sample:\n",
    "            scalograms.append(scalogram(channel, 128, 64, 0, 2))\n",
    "        scalogram_data.append(np.concatenate(scalograms))\n",
    "    return np.asarray(scalogram_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8cb0d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16940/16940 [10:05<00:00, 27.97it/s]\n"
     ]
    }
   ],
   "source": [
    "X_scalogram = generate_scalogram(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f33657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16940, 448, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scalogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e6d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16940, 448, 128, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape data\n",
    "X_scalogram = X_scalogram.reshape(X_scalogram.shape[0], X_scalogram.shape[1], X_scalogram.shape[2], 1)\n",
    "X_scalogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50914955",
   "metadata": {},
   "source": [
    "## Test-Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36368b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_scalogram, Y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc8758d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408f7755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13552, 448, 128, 1)\n",
      "y_train shape: (13552,)\n",
      "X_val shape: (3388, 448, 128, 1)\n",
      "y_val shape: (3388,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "# print(\"X_test shape:\", X_test.shape)\n",
    "# print(\"y_test shape:\", y_test.shape)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de381d5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa0fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # Set input layer\n",
    "    keras.layers.InputLayer(input_shape=input_shape),\n",
    "    \n",
    "    # Conv + Maxpooling\n",
    "    keras.layers.Conv2D(8, (3, 3), padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Normalization\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Flatten and convert from 3D to 1D\n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    # Sigmoid\n",
    "    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a166867",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b7d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 448, 128, 8)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 224, 64, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 224, 64, 8)        32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 114688)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 458756    \n",
      "=================================================================\n",
      "Total params: 458,868\n",
      "Trainable params: 458,852\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35219cc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (13552, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2c1a83de11ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/ms_project/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ms_project/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ms_project/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ms_project/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ms_project/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ms_project/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    715\u001b[0m         raise ValueError('You are passing a target array of shape ' +\n\u001b[1;32m    716\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                          \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m                          \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                          \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (13552, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cf5af",
   "metadata": {},
   "source": [
    "* Music\n",
    "    * Validation accuracy: 99.47%\n",
    "    * Validation loss: 0.0161\n",
    "* Rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.legend(['train'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "#\n",
    "# print('Test accuracy:', test_acc)\n",
    "# print('Test loss:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
